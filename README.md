## Self-distillation with Batch Knowledge Ensembling Improves ImageNet Classification


### Update

[2021-06-08] The implementation of BAKE on small-scale datasets has been added, please refer to [small_scale](small_scale/).


### Citation

If you find **BAKE** helpful in your research, please consider citing:

```
@misc{ge2020bake,
    title={Self-distillation with Batch Knowledge Ensembling Improves ImageNet Classification},
    author={Yixiao Ge and Ching Lam Choi and Xiao Zhang and Peipei Zhao and Feng Zhu and Rui Zhao and Hongsheng Li},
    year={2021},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
```
